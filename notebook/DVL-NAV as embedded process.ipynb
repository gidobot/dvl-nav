{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVL-ODO as Embedded Process\n",
    "Gregory Burgess\n",
    "\n",
    "03/26/2021\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "1. The goal of this python script is to feed in the raw PDO data and Glider flight data iteratively in order to re-create the dives from Kolumbo 2019 and test the navigation algorithms as embedded processes. Ideally, the end product of this script will be an animation of the dive in \"real-time\" that shows both the DR track as well as the DVL-ODO track over time.\n",
    "\n",
    "2. The main challenge is making sure the python classes being used to hold the DVL and flight computer data are robust enough to handle the data in an online fashion.\n",
    "\n",
    "3. The next step will be to transfer this to ROS and embed the navigation processes with the backseat driver as well as construct two interfaces (one for the actual glider, and one for the simulator). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='import-libraries'></a>\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import seaborn as sns \n",
    "import struct\n",
    "import sys\n",
    "import utm\n",
    "import unittest\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy import interpolate\n",
    "\n",
    "# add parent directory to the path for importing modules \n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "sys.path.append(os.path.join(sys.path[0], '../data'))\n",
    "\n",
    "# objects for parsing raw DVL data \n",
    "import PathfinderDVL\n",
    "import PathfinderEnsemble\n",
    "import PathfinderTimeSeries\n",
    "\n",
    "# objects for estimating ocean current velocities\n",
    "import VelocityShearPropagation\n",
    "\n",
    "# objects for controlling thruster to minimize transport cost \n",
    "import AdaptiveVelocityController\n",
    "\n",
    "# objects for parsing flight and science computer log files\n",
    "import SlocumFlightController\n",
    "import SlocumScienceController\n",
    "import dvl_plotter\n",
    "import BathymetryMap\n",
    "import MultiFactorTAN\n",
    "\n",
    "# data for parsing seafloor bathymetry\n",
    "import bathy_meta_data\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def reload_modules():\n",
    "    importlib.reload(PathfinderDVL)\n",
    "    importlib.reload(PathfinderEnsemble)\n",
    "    importlib.reload(PathfinderTimeSeries)\n",
    "    importlib.reload(VelocityShearPropagation)\n",
    "    importlib.reload(AdaptiveVelocityController)\n",
    "    importlib.reload(SlocumFlightController)\n",
    "    importlib.reload(SlocumScienceController)\n",
    "    importlib.reload(dvl_plotter)\n",
    "    importlib.reload(bathy_meta_data)\n",
    "    importlib.reload(BathymetryMap)\n",
    "    importlib.reload(MultiFactorTAN)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Glider Data, DVL data, and Bathy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Parsing folder of ASC Files\n",
      ">> Finished Parsing!\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: 01820002.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "    # ensembles:    800\n",
      "    # ensembles:   1000\n",
      "    # ensembles:   1200\n",
      "    # ensembles:   1400\n",
      "    # ensembles:   1600\n",
      "    # ensembles:   1800\n",
      "    # ensembles:   2000\n",
      "    # ensembles:   2200\n",
      "    # ensembles:   2400\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:   2410\n",
      "    parsing time:  7.385799\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: sk220034.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "    # ensembles:    800\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:    819\n",
      "    parsing time:  2.196000\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: 01820008.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:    787\n",
      "    parsing time:  2.196872\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: 01820013.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:    721\n",
      "    parsing time:  2.448005\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: sk222256.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "    # ensembles:    800\n",
      "    # ensembles:   1000\n",
      "    # ensembles:   1200\n",
      "    # ensembles:   1400\n",
      "    # ensembles:   1600\n",
      "    # ensembles:   1800\n",
      "    # ensembles:   2000\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:   2018\n",
      "    parsing time:  6.020726\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n",
      "________________________________________\n",
      "- Parsing DVL File ---------------------\n",
      "    input file: sk261222.pd0\n",
      "    # ensembles:    200\n",
      "    # ensembles:    400\n",
      "    # ensembles:    600\n",
      "    # ensembles:    800\n",
      "    # ensembles:   1000\n",
      "    # ensembles:   1200\n",
      "    # ensembles:   1400\n",
      "    # ensembles:   1600\n",
      "    # ensembles:   1800\n",
      "    # ensembles:   2000\n",
      "    # ensembles:   2200\n",
      "    # ensembles:   2400\n",
      "    # ensembles:   2600\n",
      "- Parsing Complete ---------------------\n",
      "    # ensembles:   2794\n",
      "    parsing time:  8.065117\n",
      "- Sensor Configuration -----------------\n",
      "    600kHz System\n",
      "    Convex Beam Pattern\n",
      "    Sensor Config #1\n",
      "    Attached\n",
      "    Down Facing\n",
      "    30E Beam Angle\n",
      "    4 Beam Janus\n",
      "- Coordinate Transformation ------------\n",
      "    Bin Mapping Used\n",
      "    3-Beam Soln Used\n",
      "    Tilts Used\n",
      "    Earth Coords\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "\n",
    "################## Read in Glider Data ####################\n",
    "directory = \"C:/Users/grego/Dropbox/Kolumbo cruise 2019/zduguid/dbd-parsed/sentinel_2019-Nov/\"\n",
    "ts_flight_kolumbo_all = SlocumFlightController.SlocumFlightController.from_directory(directory, save=False, verbose=False)\n",
    "\n",
    "################## Read in bathymetric data ####################\n",
    "#Grid_res_num should always be 10 to represent original resolution of the bathymetry chart. Then, the Minimum spatial resolution will be 5m\n",
    "#10m resolution\n",
    "bathy_df = pd.read_csv('C:/Users/grego/Dropbox/Kolumbo cruise 2019/zduguid/bathy/sensitivity_tests/Kolumbo-1.csv')\n",
    "grid_res_num = 10\n",
    "# map_var_resolution = '10m'\n",
    "#20m resolution\n",
    "bathy_df_var = pd.read_csv('C:/Users/grego/Dropbox/Kolumbo cruise 2019/zduguid/bathy/sensitivity_tests/Kolumbo-2.csv')\n",
    "map_var_resolution = '20m'\n",
    "\n",
    "################## Read in DVL data #########################\n",
    "glider = \"sentinel\"\n",
    "filepath = \"C:/Users/grego/Dropbox/Kolumbo cruise 2019/zduguid/pd0-raw/%s/\" % (glider)\n",
    "    #################################################\n",
    "    # File ID Number ################################\n",
    "    #################################################\n",
    "filename2  = \"sk211652.pd0\" # DIVE 2\n",
    "filename3  = \"01820002.pd0\" # DIVE 3\n",
    "filename4  = \"sk220034.pd0\" # DIVE 4\n",
    "filename5  = \"01820008.pd0\" # DIVE 5\n",
    "filename7  = \"01820013.pd0\" # DIVE 7\n",
    "filename9  = \"sk222256.pd0\" # DIVE 9\n",
    "filename12 = \"sk230350.pd0\" # DIVE 12\n",
    "filename14 = \"sk261222.pd0\" # DIVE 14\n",
    "    #################################################\n",
    "    # Parse Selected File IDs #######################\n",
    "    #################################################\n",
    "# ts2  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename2,  save=False)\n",
    "ts3  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename3,  save=False)\n",
    "ts4  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename4,  save=False)\n",
    "ts5  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename5,  save=False)\n",
    "ts7  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename7,  save=False)\n",
    "ts9  = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename9,  save=False)\n",
    "# ts12 = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename12, save=False)\n",
    "ts14 = PathfinderTimeSeries.PathfinderTimeSeries.from_pd0(filepath+filename14, save=False)\n",
    "    #################################################\n",
    "    # Frontiers (and Thesis) Naming Convention ###################\n",
    "    #################################################\n",
    "# tsb  = ts12 # (no bottom)\n",
    "# tsc  = ts2 # (no bottom)\n",
    "# tsh  = ts9 # (not included in Frontiers) (also doesn't look like too much bottom?)\n",
    "# tsd  = ts3 #(crazy dive)\n",
    "tsa  = ts14\n",
    "tse  = ts4\n",
    "tsf  = ts5\n",
    "tsg  = ts7 # (not included in Frontiers)\n",
    "    #################################################\n",
    "    # JFR Naming Convention #########################\n",
    "    #################################################\n",
    "# tsa  = ts14\n",
    "# tsb  = ts5\n",
    "# tsc  = ts4 \n",
    "# tsd  = ts3\n",
    "# tse = ts7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Dive to Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Time Series to Run Naviagation Code on\n",
    "#ts_label is purely for visual results at end (not important for code)\n",
    "ts = tsa\n",
    "dive_label = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd0_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5445fbac24b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensembles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ensembles'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpd0_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5445fbac24b4>\u001b[0m in \u001b[0;36mpd0_read\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mensembles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd0_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_pd0_bytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Chop off the ensemble we just parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd0_parser' is not defined"
     ]
    }
   ],
   "source": [
    "def pd0_read(fn):\n",
    "    data = open(fn, 'rb').read()\n",
    "    ensembles = 0\n",
    "    while len(data) > 0:\n",
    "        parsed = pd0_parser.parse_pd0_bytearray(data)\n",
    "        print(parsed)\n",
    "        # Chop off the ensemble we just parsed\n",
    "        data = data[parsed['header']['number_of_bytes'] + 2:]\n",
    "        ensembles += 1\n",
    "    print(ensembles, 'ensembles')\n",
    "\n",
    "desired_pd0_data = filename14\n",
    "file = filepath + desired_pd0_data\n",
    "\n",
    "#####Open pd0 Data ######\n",
    "data = open(file, 'rb').read()      #opens file in read mode and binary mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
